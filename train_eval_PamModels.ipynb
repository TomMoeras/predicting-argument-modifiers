{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training PamModels\n",
    "\n",
    "This notebook provides an overview of the training pipeline of the PAM (Predicting Argument Modifiers) Models in this project. It includes the code for training different models with different features. It also includes a couple of examples of the features that are extracted for training the specific model. Additionally, the classification report will be provided here as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # nopep8\n",
    "import sys  # nopep8\n",
    "from pathlib import Path  # nopep8\n",
    "\n",
    "# Add the 'src' directory to sys.path\n",
    "current_working_directory = os.getcwd()  # Get the current working directory\n",
    "src_path = (\n",
    "    Path(current_working_directory).resolve() / \"src\"\n",
    ")  # Construct the path to the 'src' directory\n",
    "sys.path.append(str(src_path))  # Add 'src' directory to sys.path\n",
    "\n",
    "from corpus import *\n",
    "from models.framework import *\n",
    "\n",
    "# path to trained models\n",
    "models_path = Path(src_path) / \"models\" / \"trained_pkl\"\n",
    "\n",
    "# define the corpus path\n",
    "corpus_path = Path(src_path).resolve() / \"corpus\" / \"md_corpus_ontonotes.pkl\"\n",
    "\n",
    "md_corpus_onto = Corpus.load_corpus(corpus_path)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Model\n",
    "\n",
    "The features for the dummy model consists of a Bag of Words (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate feature extractor\n",
    "feature_extractor = FeatureExtractor(\n",
    "    feature_methods=[\n",
    "        FeatureExtractor.bow,\n",
    "    ],\n",
    "    corpus=md_corpus_onto,\n",
    ")\n",
    "\n",
    "# Instantiate PAM model (using logistic regression for the classification task)\n",
    "bow_model = PamModel(\n",
    "    model=LogisticRegression(max_iter=300),\n",
    "    feature_extractor=feature_extractor,\n",
    "    corpus=md_corpus_onto,\n",
    "    train_data=\"train\",\n",
    "    test_data=\"dev\",\n",
    ")\n",
    "\n",
    "# Train model\n",
    "bow_model.train()\n",
    "\n",
    "# save model\n",
    "bow_model.save_model(\"dummy_bow_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "bow_model = PamModel.load_model(filename=Path(models_path) / \"dummy_bow_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accordance' 'according' 'accordingly' 'account' 'accounts' 'acquisition'\n",
      " 'across' 'act' 'action' 'active']\n"
     ]
    }
   ],
   "source": [
    "# get a list of the feature names\n",
    "feature_names = bow_model.feature_extractor.vectorizer.get_feature_names_out()\n",
    "print(feature_names[90:100])\n",
    "\n",
    "# ['accordance' 'according' 'accordingly' 'account' 'accounts' 'acquisition'\n",
    "#  'across' 'act' 'action' 'active']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADV       0.77      0.63      0.70      1074\n",
      "         DIS       0.85      0.85      0.85       954\n",
      "         LOC       0.80      0.85      0.82       766\n",
      "         MNR       0.72      0.61      0.66       675\n",
      "         MOD       0.99      0.98      0.99       898\n",
      "         NEG       0.69      0.99      0.81       549\n",
      "         TMP       0.90      0.92      0.91      1963\n",
      "\n",
      "    accuracy                           0.84      6879\n",
      "   macro avg       0.82      0.83      0.82      6879\n",
      "weighted avg       0.84      0.84      0.84      6879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bow_model.evaluate(print_report=True)\n",
    "\n",
    "# weighted average f1-score: 0.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>not</td>\n",
       "      <td>4.369207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>never</td>\n",
       "      <td>2.541671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>nt</td>\n",
       "      <td>2.296133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>no</td>\n",
       "      <td>1.352227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>nor</td>\n",
       "      <td>1.097732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>only</td>\n",
       "      <td>-2.946917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>so</td>\n",
       "      <td>-2.969488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>or</td>\n",
       "      <td>-3.027511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>and</td>\n",
       "      <td>-3.270357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>in</td>\n",
       "      <td>-3.321753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  importance\n",
       "1185     not    4.369207\n",
       "1165   never    2.541671\n",
       "1191      nt    2.296133\n",
       "1174      no    1.352227\n",
       "1178     nor    1.097732\n",
       "...      ...         ...\n",
       "1224    only   -2.946917\n",
       "1619      so   -2.969488\n",
       "1237      or   -3.027511\n",
       "155      and   -3.270357\n",
       "861       in   -3.321753\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_model.get_feature_importance(\"NEG\")\n",
    "\n",
    "\n",
    "# feature\timportance\n",
    "# 1185\tnot\t4.369207\n",
    "# 1165\tnever\t2.541671\n",
    "# 1191\tnt\t2.296133\n",
    "# 1174\tno\t1.352227\n",
    "# 1178\tnor\t1.097732\n",
    "# ...\t...\t...\n",
    "# 1224\tonly\t-2.946917\n",
    "# 1619\tso\t-2.969488\n",
    "# 1237\tor\t-3.027511\n",
    "# 155\tand\t-3.270357\n",
    "# 861\tin\t-3.321753"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"string\": \"in November 2009\", \"predicted_role\": \"TMP\"}'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_model.predict_string(\"in November 2009\")\n",
    "\n",
    "# '{\"string\": \"in November 2009\", \"predicted_role\": \"TMP\"}'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Model\n",
    "\n",
    "This functions similarly to the BoW model. However, it uses TF-IDF weighting for the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate feature extractor\n",
    "feature_extractor = FeatureExtractor(\n",
    "    feature_methods=[\n",
    "        FeatureExtractor.tfidf,\n",
    "    ],\n",
    "    corpus=md_corpus_onto,\n",
    ")\n",
    "\n",
    "# Instantiate PAM model (using logistic regression for the classification task)\n",
    "tfidf_model = PamModel(\n",
    "    model=LogisticRegression(max_iter=300),\n",
    "    feature_extractor=feature_extractor,\n",
    "    corpus=md_corpus_onto,\n",
    "    train_data=\"train\",\n",
    "    test_data=\"dev\",\n",
    ")\n",
    "\n",
    "# Train model\n",
    "tfidf_model.train()\n",
    "\n",
    "# save model\n",
    "tfidf_model.save_model(\"tfidf_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "tfidf_model = PamModel.load_model(filename=Path(models_path) / \"tfidf_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of the feature names\n",
    "feature_names = tfidf_model.feature_extractor.vectorizer.get_feature_names_out()\n",
    "print(feature_names[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADV       0.76      0.66      0.71      1074\n",
      "         DIS       0.87      0.85      0.86       954\n",
      "         LOC       0.83      0.85      0.84       766\n",
      "         MNR       0.75      0.64      0.69       675\n",
      "         MOD       1.00      0.98      0.99       898\n",
      "         NEG       0.75      0.99      0.85       549\n",
      "         TMP       0.89      0.93      0.91      1963\n",
      "\n",
      "    accuracy                           0.85      6879\n",
      "   macro avg       0.83      0.84      0.84      6879\n",
      "weighted avg       0.85      0.85      0.85      6879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_model.evaluate(print_report=True)\n",
    "\n",
    "# weighted average f1-score: 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>not</td>\n",
       "      <td>4.921588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868</th>\n",
       "      <td>never</td>\n",
       "      <td>2.594258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>nt</td>\n",
       "      <td>2.244173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>no</td>\n",
       "      <td>1.501277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>nor</td>\n",
       "      <td>0.996759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>and</td>\n",
       "      <td>-3.838011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>at</td>\n",
       "      <td>-3.946682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>on</td>\n",
       "      <td>-4.450119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4395</th>\n",
       "      <td>the</td>\n",
       "      <td>-6.017031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>in</td>\n",
       "      <td>-7.461249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  importance\n",
       "2911     not    4.921588\n",
       "2868   never    2.594258\n",
       "2927      nt    2.244173\n",
       "2889      no    1.501277\n",
       "2900     nor    0.996759\n",
       "...      ...         ...\n",
       "328      and   -3.838011\n",
       "436       at   -3.946682\n",
       "2992      on   -4.450119\n",
       "4395     the   -6.017031\n",
       "2101      in   -7.461249\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_model.get_feature_importance(\"NEG\")\n",
    "\n",
    "# \tfeature\timportance\n",
    "# 2911\tnot\t4.921588\n",
    "# 2868\tnever\t2.594258\n",
    "# 2927\tnt\t2.244173\n",
    "# 2889\tno\t1.501277\n",
    "# 2900\tnor\t0.996759\n",
    "# ...\t...\t...\n",
    "# 328\tand\t-3.838011\n",
    "# 436\tat\t-3.946682\n",
    "# 2992\ton\t-4.450119\n",
    "# 4395\tthe\t-6.017031\n",
    "# 2101\tin\t-7.461249"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"string\": \"in November 2009\", \"predicted_role\": \"TMP\"}'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_model.predict_string(\"in November 2009\")\n",
    "\n",
    "# '{\"string\": \"in November 2009\", \"predicted_role\": \"TMP\"}'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Gram Model\n",
    "\n",
    "This model uses TF-IDF weighted unigrams and bigrams as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate feature extractor\n",
    "feature_extractor = FeatureExtractor(\n",
    "    feature_methods=[\n",
    "        FeatureExtractor.ngram,\n",
    "    ],\n",
    "    corpus=md_corpus_onto,\n",
    ")\n",
    "\n",
    "# Instantiate PAM model (using logistic regression for the classification task)\n",
    "ngram_model = PamModel(\n",
    "    model=LogisticRegression(max_iter=300),\n",
    "    feature_extractor=feature_extractor,\n",
    "    corpus=md_corpus_onto,\n",
    "    train_data=\"train\",\n",
    "    test_data=\"dev\",\n",
    ")\n",
    "\n",
    "# Train model\n",
    "ngram_model.train()\n",
    "\n",
    "# save model\n",
    "ngram_model.save_model(\"ngram_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "ngram_model = PamModel.load_model(filename=Path(models_path) / \"ngram_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of the feature names\n",
    "feature_names = ngram_model.feature_extractor.vectorizer.get_feature_names_out()\n",
    "print(feature_names[90:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADV       0.77      0.69      0.73      1074\n",
      "         DIS       0.87      0.86      0.87       954\n",
      "         LOC       0.82      0.87      0.85       766\n",
      "         MNR       0.78      0.64      0.71       675\n",
      "         MOD       1.00      0.98      0.99       898\n",
      "         NEG       0.75      0.99      0.85       549\n",
      "         TMP       0.90      0.93      0.92      1963\n",
      "\n",
      "    accuracy                           0.86      6879\n",
      "   macro avg       0.84      0.85      0.84      6879\n",
      "weighted avg       0.86      0.86      0.86      6879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngram_model.evaluate(print_report=True)\n",
    "\n",
    "# weighted average f1-score: 0.86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5459</th>\n",
       "      <td>not</td>\n",
       "      <td>4.993346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5372</th>\n",
       "      <td>never</td>\n",
       "      <td>2.703227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5497</th>\n",
       "      <td>nt</td>\n",
       "      <td>2.284522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5427</th>\n",
       "      <td>no</td>\n",
       "      <td>1.721516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5445</th>\n",
       "      <td>nor</td>\n",
       "      <td>1.035561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5532</th>\n",
       "      <td>of</td>\n",
       "      <td>-4.228029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>at</td>\n",
       "      <td>-4.245273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5731</th>\n",
       "      <td>on</td>\n",
       "      <td>-4.834429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7940</th>\n",
       "      <td>the</td>\n",
       "      <td>-6.809075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>in</td>\n",
       "      <td>-8.592979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  importance\n",
       "5459     not    4.993346\n",
       "5372   never    2.703227\n",
       "5497      nt    2.284522\n",
       "5427      no    1.721516\n",
       "5445     nor    1.035561\n",
       "...      ...         ...\n",
       "5532      of   -4.228029\n",
       "1005      at   -4.245273\n",
       "5731      on   -4.834429\n",
       "7940     the   -6.809075\n",
       "3819      in   -8.592979\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_model.get_feature_importance(\"NEG\")\n",
    "\n",
    "# \tfeature\timportance\n",
    "# 5459\tnot\t4.993346\n",
    "# 5372\tnever\t2.703227\n",
    "# 5497\tnt\t2.284522\n",
    "# 5427\tno\t1.721516\n",
    "# 5445\tnor\t1.035561\n",
    "# ...\t...\t...\n",
    "# 5532\tof\t-4.228029\n",
    "# 1005\tat\t-4.245273\n",
    "# 5731\ton\t-4.834429\n",
    "# 7940\tthe\t-6.809075\n",
    "# 3819\tin\t-8.592979"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"string\": \"in November 2009\", \"predicted_role\": \"TMP\"}'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_model.predict_string(\"in November 2009\")\n",
    "\n",
    "# '{\"string\": \"in November 2009\", \"predicted_role\": \"TMP\"}'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Gram & POS\n",
    "\n",
    "This model uses the n-gram model's features as before, but also adds the POS-tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate feature extractor\n",
    "feature_extractor = FeatureExtractor(\n",
    "    feature_methods=[\n",
    "        FeatureExtractor.ngram,\n",
    "        FeatureExtractor.pos,\n",
    "    ],\n",
    "    corpus=md_corpus_onto,\n",
    ")\n",
    "\n",
    "# Instantiate PAM model (using logistic regression for the classification task)\n",
    "ngram_pos_model = PamModel(\n",
    "    model=LogisticRegression(max_iter=300),\n",
    "    feature_extractor=feature_extractor,\n",
    "    corpus=md_corpus_onto,\n",
    "    train_data=\"train\",\n",
    "    test_data=\"dev\",\n",
    ")\n",
    "\n",
    "# Train model\n",
    "ngram_pos_model.train()\n",
    "\n",
    "# save model\n",
    "ngram_pos_model.save_model(\"ngram_pos_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of the feature names\n",
    "feature_names = ngram_pos_model.feature_extractor.pos_encoder.get_feature_names_out()\n",
    "print(feature_names[90:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "ngram_pos_model = PamModel.load_model(filename=Path(models_path) / \"ngram_pos_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADV       0.76      0.69      0.72      1074\n",
      "         DIS       0.86      0.87      0.86       954\n",
      "         LOC       0.84      0.87      0.86       766\n",
      "         MNR       0.74      0.72      0.73       675\n",
      "         MOD       1.00      0.98      0.99       898\n",
      "         NEG       0.90      0.93      0.91       549\n",
      "         TMP       0.90      0.93      0.92      1963\n",
      "\n",
      "    accuracy                           0.86      6879\n",
      "   macro avg       0.86      0.86      0.86      6879\n",
      "weighted avg       0.86      0.86      0.86      6879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngram_pos_model.evaluate(print_report=True)\n",
    "\n",
    "# weighted average f1-score: 0.86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5459</th>\n",
       "      <td>not</td>\n",
       "      <td>5.188587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5372</th>\n",
       "      <td>never</td>\n",
       "      <td>4.430910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>x0_PART</td>\n",
       "      <td>4.236774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5427</th>\n",
       "      <td>no</td>\n",
       "      <td>2.887181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5497</th>\n",
       "      <td>nt</td>\n",
       "      <td>2.638690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>and</td>\n",
       "      <td>-2.847569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5731</th>\n",
       "      <td>on</td>\n",
       "      <td>-2.977937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5532</th>\n",
       "      <td>of</td>\n",
       "      <td>-3.022960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7940</th>\n",
       "      <td>the</td>\n",
       "      <td>-4.990417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>in</td>\n",
       "      <td>-5.673898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18146 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "5459       not    5.188587\n",
       "5372     never    4.430910\n",
       "14636  x0_PART    4.236774\n",
       "5427        no    2.887181\n",
       "5497        nt    2.638690\n",
       "...        ...         ...\n",
       "596        and   -2.847569\n",
       "5731        on   -2.977937\n",
       "5532        of   -3.022960\n",
       "7940       the   -4.990417\n",
       "3819        in   -5.673898\n",
       "\n",
       "[18146 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_pos_model.get_feature_importance(\"NEG\")\n",
    "\n",
    "# \tfeature\timportance\n",
    "# 5459\tnot\t5.188587\n",
    "# 5372\tnever\t4.430910\n",
    "# 14636\tx0_PART\t4.236774\n",
    "# 5427\tno\t2.887181\n",
    "# 5497\tnt\t2.638690\n",
    "# ...\t...\t...\n",
    "# 596\tand\t-2.847569\n",
    "# 5731\ton\t-2.977937\n",
    "# 5532\tof\t-3.022960\n",
    "# 7940\tthe\t-4.990417\n",
    "# 3819\tin\t-5.673898"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"string\": \"in November 2009\", \"predicted_role\": \"TMP\"}'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_pos_model.predict_string(\"in November 2009\")\n",
    "\n",
    "# '{\"string\": \"in November 2009\", \"predicted_role\": \"TMP\"}'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Gram, POS & NER Model\n",
    "\n",
    "This model uses the n-gram_pos model's features as before, but also adds the NER-tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate feature extractor\n",
    "feature_extractor = FeatureExtractor(\n",
    "    feature_methods=[\n",
    "        FeatureExtractor.ngram,\n",
    "        FeatureExtractor.pos,\n",
    "        FeatureExtractor.ner,\n",
    "    ],\n",
    "    corpus=md_corpus_onto,\n",
    ")\n",
    "\n",
    "# Instantiate PAM model (using logistic regression for the classification task)\n",
    "ngram_pos_ner_model = PamModel(\n",
    "    model=LogisticRegression(max_iter=500),\n",
    "    feature_extractor=feature_extractor,\n",
    "    corpus=md_corpus_onto,\n",
    "    train_data=\"train\",\n",
    "    test_data=\"dev\",\n",
    ")\n",
    "\n",
    "# Train model\n",
    "ngram_pos_ner_model.train()\n",
    "\n",
    "# save model\n",
    "ngram_pos_ner_model.save_model(\"ngram_pos_ner_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "ngram_pos_ner_model = PamModel.load_model(filename=Path(models_path) / \"ngram_pos_ner_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of the feature names\n",
    "feature_names = ngram_pos_ner_model.feature_extractor.ner_encoder.get_feature_names_out()\n",
    "print(feature_names[90:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADV       0.76      0.69      0.72      1074\n",
      "         DIS       0.87      0.87      0.87       954\n",
      "         LOC       0.83      0.88      0.86       766\n",
      "         MNR       0.74      0.72      0.73       675\n",
      "         MOD       1.00      0.98      0.99       898\n",
      "         NEG       0.90      0.93      0.91       549\n",
      "         TMP       0.90      0.93      0.92      1963\n",
      "\n",
      "    accuracy                           0.87      6879\n",
      "   macro avg       0.86      0.86      0.86      6879\n",
      "weighted avg       0.86      0.87      0.86      6879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngram_pos_ner_model.evaluate(print_report=True)\n",
    "\n",
    "# weighted average f1-score: 0.86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5459</th>\n",
       "      <td>not</td>\n",
       "      <td>5.208589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5372</th>\n",
       "      <td>never</td>\n",
       "      <td>4.407519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>x0_PART</td>\n",
       "      <td>4.108050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5427</th>\n",
       "      <td>no</td>\n",
       "      <td>2.890373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5497</th>\n",
       "      <td>nt</td>\n",
       "      <td>2.518744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>and</td>\n",
       "      <td>-2.836572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5532</th>\n",
       "      <td>of</td>\n",
       "      <td>-2.979627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5731</th>\n",
       "      <td>on</td>\n",
       "      <td>-2.981826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7940</th>\n",
       "      <td>the</td>\n",
       "      <td>-4.977608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>in</td>\n",
       "      <td>-5.635395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18764 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "5459       not    5.208589\n",
       "5372     never    4.407519\n",
       "14636  x0_PART    4.108050\n",
       "5427        no    2.890373\n",
       "5497        nt    2.518744\n",
       "...        ...         ...\n",
       "596        and   -2.836572\n",
       "5532        of   -2.979627\n",
       "5731        on   -2.981826\n",
       "7940       the   -4.977608\n",
       "3819        in   -5.635395\n",
       "\n",
       "[18764 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_pos_ner_model.get_feature_importance(\"NEG\")\n",
    "\n",
    "# \tfeature\timportance\n",
    "# 5459\tnot\t5.208589\n",
    "# 5372\tnever\t4.407519\n",
    "# 14636\tx0_PART\t4.108050\n",
    "# 5427\tno\t2.890373\n",
    "# 5497\tnt\t2.518744\n",
    "# ...\t...\t...\n",
    "# 596\tand\t-2.836572\n",
    "# 5532\tof\t-2.979627\n",
    "# 5731\ton\t-2.981826\n",
    "# 7940\tthe\t-4.977608\n",
    "# 3819\tin\t-5.635395"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"string\": \"in November 2009\", \"predicted_role\": \"TMP\"}'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_pos_ner_model.predict_string(\"in November 2009\")\n",
    "\n",
    "# '{\"string\": \"in November 2009\", \"predicted_role\": \"TMP\"}'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Gram, POS, NER & Dependency Model\n",
    "\n",
    "This model uses the n-gram_pos_ner model's features as before, but also adds the dependency structure as feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate feature extractor\n",
    "feature_extractor = FeatureExtractor(\n",
    "    feature_methods=[\n",
    "        FeatureExtractor.ngram,\n",
    "        FeatureExtractor.pos,\n",
    "        FeatureExtractor.ner,\n",
    "        FeatureExtractor.get_dependency_features\n",
    "    ],\n",
    "    corpus=md_corpus_onto,\n",
    ")\n",
    "\n",
    "# Instantiate PAM model (using logistic regression for the classification task)\n",
    "ngram_pos_ner_dep_model = PamModel(\n",
    "    model=LogisticRegression(max_iter=500),\n",
    "    feature_extractor=feature_extractor,\n",
    "    corpus=md_corpus_onto,\n",
    "    train_data=\"train\",\n",
    "    test_data=\"dev\",\n",
    ")\n",
    "\n",
    "# Train model\n",
    "ngram_pos_ner_dep_model.train()\n",
    "\n",
    "# save model\n",
    "ngram_pos_ner_dep_model.save_model(\"ngram_pos_ner_dep_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "ngram_pos_ner_dep_model = PamModel.load_model(filename=Path(models_path) / \"ngram_pos_ner_dep_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of the feature names\n",
    "feature_names = ngram_pos_ner_dep_model.feature_extractor.dep_encoder.get_feature_names_out()\n",
    "print(feature_names[90:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADV       0.74      0.70      0.72      1074\n",
      "         DIS       0.88      0.84      0.86       954\n",
      "         LOC       0.82      0.88      0.85       766\n",
      "         MNR       0.76      0.75      0.75       675\n",
      "         MOD       1.00      0.99      1.00       898\n",
      "         NEG       0.97      0.99      0.98       549\n",
      "         TMP       0.91      0.93      0.92      1963\n",
      "\n",
      "    accuracy                           0.87      6879\n",
      "   macro avg       0.87      0.87      0.87      6879\n",
      "weighted avg       0.87      0.87      0.87      6879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngram_pos_ner_dep_model.evaluate(print_report=True)\n",
    "\n",
    "# weighted average f1-score: 0.87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5459</th>\n",
       "      <td>not</td>\n",
       "      <td>5.207504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5372</th>\n",
       "      <td>never</td>\n",
       "      <td>3.152983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5427</th>\n",
       "      <td>no</td>\n",
       "      <td>2.653509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5497</th>\n",
       "      <td>nt</td>\n",
       "      <td>2.618150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>x0_PART</td>\n",
       "      <td>2.238358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>and</td>\n",
       "      <td>-2.719431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5532</th>\n",
       "      <td>of</td>\n",
       "      <td>-2.890461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5731</th>\n",
       "      <td>on</td>\n",
       "      <td>-2.947505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7940</th>\n",
       "      <td>the</td>\n",
       "      <td>-4.875818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>in</td>\n",
       "      <td>-5.579103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29668 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "5459       not    5.207504\n",
       "5372     never    3.152983\n",
       "5427        no    2.653509\n",
       "5497        nt    2.618150\n",
       "14636  x0_PART    2.238358\n",
       "...        ...         ...\n",
       "596        and   -2.719431\n",
       "5532        of   -2.890461\n",
       "5731        on   -2.947505\n",
       "7940       the   -4.875818\n",
       "3819        in   -5.579103\n",
       "\n",
       "[29668 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_pos_ner_dep_model.get_feature_importance(\"NEG\")\n",
    "\n",
    "# \tfeature\timportance\n",
    "# 5459\tnot\t5.207504\n",
    "# 5372\tnever\t3.152983\n",
    "# 5427\tno\t2.653509\n",
    "# 5497\tnt\t2.618150\n",
    "# 14636\tx0_PART\t2.238358\n",
    "# ...\t...\t...\n",
    "# 596\tand\t-2.719431\n",
    "# 5532\tof\t-2.890461\n",
    "# 5731\ton\t-2.947505\n",
    "# 7940\tthe\t-4.875818\n",
    "# 3819\tin\t-5.579103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"string\": \"in November 2009\", \"predicted_role\": \"TMP\"}'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_pos_ner_dep_model.predict_string(\"in November 2009\")\n",
    "\n",
    "# '{\"string\": \"in November 2009\", \"predicted_role\": \"TMP\"}'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Gram, POS, NER, DEP & Constituency Model\n",
    "\n",
    "This model uses the n-gram_pos_ner_dep model's features as before, but also adds the constituency structure as feature.\n",
    "\n",
    "Note that extracting the constituency features takes some time as they are generated with the `benepar` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate feature extractor\n",
    "feature_extractor = FeatureExtractor(\n",
    "    feature_methods=[\n",
    "        FeatureExtractor.ngram,\n",
    "        FeatureExtractor.pos,\n",
    "        FeatureExtractor.ner,\n",
    "        FeatureExtractor.get_dependency_features,\n",
    "        FeatureExtractor.get_constituency_features,\n",
    "    ],\n",
    "    corpus=md_corpus_onto,\n",
    ")\n",
    "\n",
    "# Instantiate PAM model (using logistic regression for the classification task)\n",
    "ngram_pos_ner_dep_const_model = PamModel(\n",
    "    model=LogisticRegression(max_iter=600), # for faster training, use LogisticRegression(penalty='l2', C=1.0, class_weight='balanced', solver='saga', max_iter=600)\n",
    "    feature_extractor=feature_extractor,\n",
    "    corpus=md_corpus_onto,\n",
    "    train_data=\"train\",\n",
    "    test_data=\"dev\",\n",
    ")\n",
    "\n",
    "# Train model\n",
    "ngram_pos_ner_dep_const_model.train()\n",
    "\n",
    "# save model\n",
    "ngram_pos_ner_dep_const_model.save_model(\"ngram_pos_ner_dep_const_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "ngram_pos_ner_dep_const_model = PamModel.load_model(filename=Path(models_path) / \"ngram_pos_ner_dep_const_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of the feature names\n",
    "feature_names = ngram_pos_ner_dep_const_model.feature_extractor.constituency_encoder.get_feature_names_out()\n",
    "print(feature_names[90:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_pos_ner_dep_const_model.evaluate(print_report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_pos_ner_dep_const_model.get_feature_importance(\"NEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_pos_ner_dep_const_model.predict_string_from_sentence(role_string=\"in November 2009\", sentence_string=\"Susan married in November 2009.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy-Sentence-Bert Model\n",
    "\n",
    "This feature extraction method processes the input data to extract sentence embeddings (vectors) for each string in the data using Sentence-BERT (`en_stsb_distilbert_base`) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate feature extractor\n",
    "feature_extractor = FeatureExtractor(\n",
    "    feature_methods=[\n",
    "        FeatureExtractor.get_sentence_bert_features\n",
    "    ],\n",
    "    corpus=md_corpus_onto,\n",
    ")\n",
    "\n",
    "# Instantiate PAM model (using logistic regression for the classification task)\n",
    "sbert_model = PamModel(\n",
    "    model=LogisticRegression(max_iter=300), # for faster training, use LogisticRegression(penalty='l2', C=1.0, class_weight='balanced', solver='saga', max_iter=300)\n",
    "    feature_extractor=feature_extractor,\n",
    "    corpus=md_corpus_onto,\n",
    "    train_data=\"train\",\n",
    "    test_data=\"dev\",\n",
    ")\n",
    "\n",
    "# Train model\n",
    "sbert_model.train()\n",
    "\n",
    "# save model\n",
    "sbert_model.save_model(\"sbert_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "sbert_model = PamModel.load_model(filename=Path(models_path) / \"sbert_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADV       0.73      0.68      0.71      1074\n",
      "         DIS       0.86      0.90      0.88       954\n",
      "         LOC       0.85      0.84      0.84       766\n",
      "         MNR       0.76      0.72      0.74       675\n",
      "         MOD       1.00      1.00      1.00       898\n",
      "         NEG       0.98      0.99      0.98       549\n",
      "         TMP       0.90      0.93      0.92      1963\n",
      "\n",
      "    accuracy                           0.87      6879\n",
      "   macro avg       0.87      0.87      0.87      6879\n",
      "weighted avg       0.87      0.87      0.87      6879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sbert_model.evaluate(print_report=True)\n",
    "\n",
    "# weighted average f1-score: 0.87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"string\": \"in November 2009\", \"predicted_role\": \"TMP\"}'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbert_model.predict_string(\"in November 2009\")\n",
    "\n",
    "# '{\"string\": \"in November 2009\", \"predicted_role\": \"TMP\"}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predicting-argument-modifiers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
